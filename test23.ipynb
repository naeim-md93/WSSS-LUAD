{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.backends import cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import src.utils.custom_transformations as CT\n",
    "from src.utils import datautils, pyutils, torchutils, metrics, imgutils\n",
    "\n",
    "cudnn.enabled = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import shutil\n",
    "#\n",
    "# os.makedirs('test/data', exist_ok=True)\n",
    "# maximum = np.array([789, 156, 42, 808])\n",
    "# counts = np.array([0, 0, 0, 0])\n",
    "# chosen = []\n",
    "# available = os.listdir(path='datasets/LUAD-HistoSeg/train')\n",
    "# done = counts >= maximum\n",
    "# while np.sum(done) < 4:\n",
    "#     img_name = random.choice(available)\n",
    "#     picked = False\n",
    "#     labels = np.array([int(img_name[-12]), int(img_name[-10]), int(img_name[-8]), int(img_name[-6])])\n",
    "#\n",
    "#     if (not done[2]) and (labels[2] == 1) and (not picked):\n",
    "#         chosen.append(img_name)\n",
    "#         counts += labels\n",
    "#         picked = True\n",
    "#\n",
    "#     if (not done[1]) and (labels[1] == 1) and (not picked):\n",
    "#         chosen.append(img_name)\n",
    "#         counts += labels\n",
    "#         picked = True\n",
    "#\n",
    "#     if (not done[0]) and (labels[0] == 1) and (not picked):\n",
    "#         chosen.append(img_name)\n",
    "#         counts += labels\n",
    "#         picked = True\n",
    "#\n",
    "#     if (not done[3]) and (labels[3] == 1) and (not picked):\n",
    "#         chosen.append(img_name)\n",
    "#         counts += labels\n",
    "#         picked = True\n",
    "#\n",
    "#     if picked:\n",
    "#         available = [x for x in available if x != img_name]\n",
    "#\n",
    "#     done = counts >= maximum\n",
    "#\n",
    "# for im in chosen:\n",
    "#     shutil.copy(src=f'datasets/LUAD-HistoSeg/train/{im}', dst=f'test/data/{im}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, first_stride, first_dilation_padding, dilation_padding):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.same_shape = (in_channels == out_channels)\n",
    "\n",
    "        self.bn_branch2a = nn.BatchNorm2d(num_features=in_channels)\n",
    "        self.relu_branch2a = nn.ReLU()\n",
    "        self.conv_branch2a = nn.Conv2d(in_channels=in_channels, out_channels=mid_channels, kernel_size=3, stride=first_stride, padding=first_dilation_padding, dilation=first_dilation_padding, bias=False)\n",
    "\n",
    "        self.bn_branch2b1 = nn.BatchNorm2d(num_features=mid_channels)\n",
    "        self.relu_branch2b1 = nn.ReLU()\n",
    "        self.conv_branch2b1 = nn.Conv2d(in_channels=mid_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=dilation_padding, dilation=dilation_padding, bias=False)\n",
    "\n",
    "        if not self.same_shape:\n",
    "            self.conv_branch1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=first_stride, bias=False)\n",
    "\n",
    "    def forward(self, x, mu=None, gamma=None, cam=None):\n",
    "\n",
    "        branch2 = self.bn_branch2a(x)\n",
    "        branch2 = self.relu_branch2a(branch2)\n",
    "\n",
    "        x_bn_relu = branch2\n",
    "\n",
    "        if (mu is not None) and (gamma is not None) and (cam is not None):\n",
    "            branch2 = intermediate_forward_PDA(x=x, mu=mu, gamma=gamma, cam=cam)\n",
    "\n",
    "        if not self.same_shape:\n",
    "            branch1 = self.conv_branch1(branch2)\n",
    "        else:\n",
    "            branch1 = x\n",
    "\n",
    "        branch2 = self.conv_branch2a(branch2)\n",
    "\n",
    "        branch2 = self.bn_branch2b1(branch2)\n",
    "        branch2 = self.relu_branch2b1(branch2)\n",
    "        branch2 = self.conv_branch2b1(branch2)\n",
    "\n",
    "        x = branch2 + branch1\n",
    "\n",
    "        return x, x_bn_relu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ResBlockBottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation_padding=1, dropout=0.0):\n",
    "        super(ResBlockBottleneck, self).__init__()\n",
    "\n",
    "        self.same_shape = (in_channels == out_channels)\n",
    "\n",
    "        self.bn_branch2a = nn.BatchNorm2d(num_features=in_channels)\n",
    "        self.relu_branch2a = nn.ReLU()\n",
    "        self.conv_branch2a = nn.Conv2d(in_channels=in_channels, out_channels=out_channels // 4, kernel_size=1, bias=False)\n",
    "\n",
    "        self.bn_branch2b1 = nn.BatchNorm2d(num_features=out_channels // 4)\n",
    "        self.relu_branch2b1 = nn.ReLU()\n",
    "        self.conv_branch2b1 = nn.Conv2d(in_channels=out_channels // 4, out_channels=out_channels // 2, kernel_size=3, padding=dilation_padding, dilation=dilation_padding, bias=False)\n",
    "\n",
    "        self.bn_branch2b2 = nn.BatchNorm2d(num_features=out_channels // 2)\n",
    "        self.relu_branch2b2 = nn.ReLU()\n",
    "        self.dropout_branch2b2 = nn.Dropout2d(p=dropout)\n",
    "        self.conv_branch2b2 = nn.Conv2d(in_channels=out_channels // 2, out_channels=out_channels, kernel_size=1, bias=False)\n",
    "\n",
    "        if not self.same_shape:\n",
    "            self.conv_branch1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x, mu=None, gamma=None, cam=None):\n",
    "\n",
    "        branch2 = self.bn_branch2a(x)\n",
    "        branch2 = self.relu_branch2a(branch2)\n",
    "\n",
    "        x_bn_relu = branch2\n",
    "\n",
    "        if (mu is not None) and (gamma is not None) and (cam is not None):\n",
    "            branch2 = intermediate_forward_PDA(x=x, mu=mu, gamma=gamma, cam=cam)\n",
    "\n",
    "        if not self.same_shape:\n",
    "            branch1 = self.conv_branch1(branch2)\n",
    "        else:\n",
    "            branch1 = x\n",
    "\n",
    "        branch2 = self.conv_branch2a(branch2)\n",
    "\n",
    "        branch2 = self.bn_branch2b1(branch2)\n",
    "        branch2 = self.relu_branch2b1(branch2)\n",
    "        branch2 = self.conv_branch2b1(branch2)\n",
    "\n",
    "        branch2 = self.bn_branch2b2(branch2)\n",
    "        branch2 = self.relu_branch2b2(branch2)\n",
    "        branch2 = self.conv_branch2b2(branch2)\n",
    "\n",
    "        x = branch1 + branch2\n",
    "\n",
    "        return x, x_bn_relu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ResNet38ClassificationModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet38ClassificationModel, self).__init__()\n",
    "\n",
    "        self.enable_PDA = [False, False, False, False, False]\n",
    "        self.mu = [1, 1, 1, 1, 1]\n",
    "        self.gamma = [0, 0, 0, 0, 0]\n",
    "\n",
    "        self.conv1a = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        #  -------- B1 -----------#\n",
    "        # Input size = (224, 224),\n",
    "        # So no B1 layer\n",
    "\n",
    "        # -------- B2 -----------#\n",
    "        self.res2a = ResBlock(in_channels=64, mid_channels=128, out_channels=128, first_stride=2, first_dilation_padding=1, dilation_padding=1)\n",
    "        self.res2b1 = ResBlock(in_channels=128, mid_channels=128, out_channels=128, first_stride=1, first_dilation_padding=1, dilation_padding=1)\n",
    "        self.res2b2 = ResBlock(in_channels=128, mid_channels=128, out_channels=128, first_stride=1, first_dilation_padding=1, dilation_padding=1)\n",
    "\n",
    "        # -------- B3 -----------#\n",
    "        self.res3a = ResBlock(in_channels=128, mid_channels=256, out_channels=256, first_stride=2, first_dilation_padding=1, dilation_padding=1)\n",
    "        self.res3b1 = ResBlock(in_channels=256, mid_channels=256, out_channels=256, first_stride=1, first_dilation_padding=1, dilation_padding=1)\n",
    "        self.res3b2 = ResBlock(in_channels=256, mid_channels=256, out_channels=256, first_stride=1, first_dilation_padding=1, dilation_padding=1)\n",
    "\n",
    "        # -------- B4 -----------#\n",
    "        self.res4a = ResBlock(in_channels=256, mid_channels=512, out_channels=512, first_stride=2, first_dilation_padding=1, dilation_padding=1)\n",
    "        self.res4b1 = ResBlock(in_channels=512, mid_channels=512, out_channels=512, first_stride=1, first_dilation_padding=1, dilation_padding=1)\n",
    "        self.res4b2 = ResBlock(in_channels=512, mid_channels=512, out_channels=512, first_stride=1, first_dilation_padding=1, dilation_padding=1)\n",
    "        self.res4b3 = ResBlock(in_channels=512, mid_channels=512, out_channels=512, first_stride=1, first_dilation_padding=1, dilation_padding=1)\n",
    "        self.res4b4 = ResBlock(in_channels=512, mid_channels=512, out_channels=512, first_stride=1, first_dilation_padding=1, dilation_padding=1)\n",
    "        self.res4b5 = ResBlock(in_channels=512, mid_channels=512, out_channels=512, first_stride=1, first_dilation_padding=1, dilation_padding=1)\n",
    "\n",
    "        # -------- B5 -----------#\n",
    "        self.res5a = ResBlock(in_channels=512, mid_channels=512, out_channels=1024, first_stride=1, first_dilation_padding=1, dilation_padding=2)\n",
    "        self.res5b1 = ResBlock(in_channels=1024, mid_channels=512, out_channels=1024, first_stride=1, first_dilation_padding=2, dilation_padding=2)\n",
    "        self.res5b2 = ResBlock(in_channels=1024, mid_channels=512, out_channels=1024, first_stride=1, first_dilation_padding=2, dilation_padding=2)\n",
    "\n",
    "        # -------- B6 -----------#\n",
    "        self.res6a = ResBlockBottleneck(in_channels=1024, out_channels=2048, dilation_padding=4, dropout=0.3)\n",
    "\n",
    "        # -------- B7 -----------#\n",
    "        self.res7a = ResBlockBottleneck(in_channels=2048, out_channels=4096, dilation_padding=4, dropout=0.5)\n",
    "        self.bn7 = nn.BatchNorm2d(num_features=4096)\n",
    "        self.relu7 = nn.ReLU()\n",
    "        # -----------------------#\n",
    "\n",
    "        self.dropout = nn.Dropout2d(p=0.5)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc8 = nn.Conv2d(in_channels=4096, out_channels=num_classes, kernel_size=1, bias=False)\n",
    "\n",
    "        nn.init.xavier_uniform_(tensor=self.fc8.weight)\n",
    "        self.not_training = [self.conv1a, self.res2a, self.res2b1, self.res2b2]\n",
    "        self.from_scratch_layers = [self.fc8]\n",
    "\n",
    "    def extract_features(self, imgs, cam=None):\n",
    "\n",
    "        x = self.conv1a(imgs)  # (b, 64, 224, 224)\n",
    "\n",
    "        # -------- B2 -----------#\n",
    "        # if self.enable_PDA[0] and (cam is not None):\n",
    "        #     x, x1a = self.res2a(x=x, cam=cam, mu=self.mu[0], gamma=self.gamma[0])  # (b, 128, 112, 112), (b, 64, 224, 224)\n",
    "        # else:\n",
    "        x, x1a = self.res2a(x=x)  # (b, 128, 112, 112), (b, 64, 224, 224)\n",
    "        x, x2a = self.res2b1(x=x)  # (b, 128, 112, 112), (b, 128, 112, 112)\n",
    "        x, x2b1 = self.res2b2(x=x)  # (b, 128, 112, 112), (b, 128, 112, 112)\n",
    "\n",
    "        # -------- B3 -----------#\n",
    "        # if self.enable_PDA[0] and (cam is not None):\n",
    "        #     x, x2b2 = self.res3a(x=x, cam=cam, mu=self.mu[1], gamma=self.gamma[1])  # (b, 256, 56, 56), (b, 128, 112, 112)\n",
    "        # else:\n",
    "        x, x2b2 = self.res3a(x=x)  # (b, 256, 56, 56), (b, 128, 112, 112)\n",
    "        x, x3a = self.res3b1(x=x)  # (b, 256, 56, 56), (b, 256, 56, 56)\n",
    "        x, x3b1 = self.res3b2(x=x)  # (b, 256, 56, 56), (b, 256, 56, 56)\n",
    "\n",
    "        # -------- B4 -----------#\n",
    "        # if self.enable_PDA[0] and (cam is not None):\n",
    "        #     x, x3b2 = self.res4a(x=x, cam=cam, mu=self.mu[2], gamma=self.gamma[2])  # (b, 512, 28, 28), (b, 256, 56, 56)\n",
    "        # else:\n",
    "        x, x3b2 = self.res4a(x=x)  # (b, 512, 28, 28), (b, 256, 56, 56)\n",
    "        x, x4a = self.res4b1(x=x)  # (b, 512, 28, 28), (b, 512, 28, 28)\n",
    "        x, x4b1 = self.res4b2(x=x)  # (b, 512, 28, 28), (b, 512, 28, 28)\n",
    "        x, x4b2 = self.res4b3(x=x)  # (b, 512, 28, 28), (b, 512, 28, 28)\n",
    "        x, x4b3 = self.res4b4(x=x)  # (b, 512, 28, 28), (b, 512, 28, 28)\n",
    "        x, x4b4 = self.res4b5(x=x)  # (b, 512, 28, 28), (b, 512, 28, 28)\n",
    "\n",
    "        # -------- B5 -----------#\n",
    "        # if self.enable_PDA[3] and (cam is not None):\n",
    "        #     x, x4b5 = self.res5a(x=x, cam=cam, mu=self.mu[3], gamma=self.gamma[3])  # (b, 1024, 28, 28), (b, 512, 28, 28)\n",
    "        # else:\n",
    "        x, x4b5 = self.res5a(x=x)  # (b, 1024, 28, 28), (b, 512, 28, 28)\n",
    "        x, x5a = self.res5b1(x=x)  # (b, 1024, 28, 28), (b, 1024, 28, 28)\n",
    "        x, x5b1 = self.res5b2(x=x)  # (b, 1024, 28, 28), (b, 1024, 28, 28)\n",
    "\n",
    "        # -------- B6 -----------#\n",
    "        x, x5b2 = self.res6a(x=x)  # (b, 2048, 28, 28), (b, 1024, 28, 28)\n",
    "\n",
    "        # -------- B7 -----------#\n",
    "        x, x6a = self.res7a(x=x)  # (b, 4096, 28, 28), (b, 2048, 28, 28)\n",
    "        x = self.bn7(x)  # (b, 4096, 28, 28)\n",
    "        x = self.relu7(x)  # (b, 4096, 28, 28)\n",
    "        # -----------------------#\n",
    "\n",
    "        # if self.enable_PDA[4] and (cam is not None):\n",
    "        #     x = final_forward_PDA(x=x, w=self.fc8.weight, mu=self.mu[4], gamma=self.gamma[4])  # (b, 4096, 28, 28)\n",
    "\n",
    "        return {\n",
    "            'x1a': x1a,\n",
    "\n",
    "            'x2a': x2a,\n",
    "            'x2b1': x2b1,\n",
    "            'x2b2': x2b2,\n",
    "\n",
    "            'x3a': x3a,\n",
    "            'x3b1': x3b1,\n",
    "            'x3b2': x3b2,\n",
    "\n",
    "            'x4a': x4a,\n",
    "            'x4b1': x4b1,\n",
    "            'x4b2': x4b2,\n",
    "            'x4b3': x4b3,\n",
    "            'x4b4': x4b4,\n",
    "            'x4b5': x4b5,\n",
    "\n",
    "            'x5a': x5a,\n",
    "            'x5b1': x5b1,\n",
    "            'x5b2': x5b2,\n",
    "\n",
    "            'x6a': x6a,\n",
    "\n",
    "            'x7a': x\n",
    "        }\n",
    "\n",
    "    def make_cam(self, x):  # (b, 3, 224, 224)\n",
    "        with torch.no_grad():\n",
    "            x7a = self.extract_features(imgs=x, cam=None)['x7a']  # (b, 4096, 28, 28)\n",
    "\n",
    "            cam = torch.conv2d(input=x7a, weight=self.fc8.weight)  # (b, 4, 28, 28)\n",
    "            cam = torch.relu(input=cam)  # (b, 4, 28, 28)\n",
    "\n",
    "            cam = torchutils.standard_scale(x=cam, dims=-3)\n",
    "        return cam  # (b, 4, 28, 28)\n",
    "\n",
    "    def forward(self, x):  # (b, 3, 224, 224)\n",
    "        ##########################################\n",
    "        cam = self.make_cam(x=x) if (sum(self.enable_PDA) > 0) else None  # (b, 4, 28, 28)\n",
    "        ##########################################\n",
    "        x = self.extract_features(imgs=x, cam=cam)['x7a']  # (b, 4096, 28, 28)\n",
    "        x = self.dropout(x)  # (b, 4096, 28, 28)\n",
    "        x = self.avgpool(x)  # (b, 4096, 1, 1)\n",
    "        x = self.fc8(x)  # (b, 4, 1, 1)\n",
    "        return x  # (b, 4, 1, 1)\n",
    "\n",
    "    def forward_cam(self, x):  # (b, 3, 224, 224)\n",
    "        x = self.extract_features(imgs=x, cam=None)['x7a']  # (b, 4096, 28, 28)\n",
    "\n",
    "        cam = torch.conv2d(input=x, weight=self.fc8.weight)  # (b, 4, 28, 28)\n",
    "        cam = torch.relu(input=cam)  # (b, 4, 28, 28)\n",
    "\n",
    "        z = self.avgpool(x)  # (b, 4096, 1, 1)\n",
    "        z = self.fc8(z)  # (b, 4, 1, 1)\n",
    "        z = torch.sigmoid(input=z)  # (b, 4, 1, 1)\n",
    "\n",
    "        return cam, z  # (b, 4, 28, 28), (b, 4, 1, 1)\n",
    "\n",
    "    def get_parameter_groups(self):\n",
    "        groups = ([], [], [], [], [], [])\n",
    "\n",
    "        for m in self.modules():\n",
    "\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "\n",
    "                if m in self.not_training:\n",
    "                    groups[0].append(m.weight)\n",
    "                elif m in self.from_scratch_layers:\n",
    "                    groups[4].append(m.weight)\n",
    "                else:\n",
    "                    groups[2].append(m.weight)\n",
    "\n",
    "                if m.bias is not None:\n",
    "                    if m in self.not_training:\n",
    "                        groups[1].append(m.bias)\n",
    "                    elif m in self.from_scratch_layers:\n",
    "                        groups[5].append(m.bias)\n",
    "                    else:\n",
    "                        groups[3].append(m.bias)\n",
    "\n",
    "        return groups\n",
    "\n",
    "    def train(self, mode=True, TL=True):\n",
    "        super(ResNet38ClassificationModel, self).train(mode)\n",
    "\n",
    "        for layer in self.not_training:\n",
    "\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                layer.weight.requires_grad = False if TL else True\n",
    "                if layer.bias is not None:\n",
    "                    layer.bias.requires_grad = False if TL else True\n",
    "\n",
    "            elif isinstance(layer, nn.Module):\n",
    "                for c in layer.children():\n",
    "                    if hasattr(c, 'weight'):\n",
    "                        c.weight.requires_grad = False if TL else True\n",
    "                    if hasattr(c, 'bias'):\n",
    "                        if c.bias is not None:\n",
    "                            c.bias.requires_grad = False if TL else True\n",
    "\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.BatchNorm2d):\n",
    "                layer.eval()\n",
    "                layer.bias.requires_grad = False\n",
    "                layer.weight.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Engine:\n",
    "    def __init__(\n",
    "            self,\n",
    "            train_cls_log_path,\n",
    "            val_cls_log_path,\n",
    "            val_cam_log_path,\n",
    "            test_cam_log_path,\n",
    "            train_data_path,\n",
    "            val_data_path,\n",
    "            test_data_path,\n",
    "            init_weights,\n",
    "            init_weights_path,\n",
    "            checkpoints_path,\n",
    "            device,\n",
    "            val_size,\n",
    "            batch_size,\n",
    "            num_classes,\n",
    "            session_name,\n",
    "            max_epochs,\n",
    "            lr,\n",
    "            wt_dec,\n",
    "            start_PDA,\n",
    "            sigma,\n",
    "            l,\n",
    "            gamma\n",
    "    ):\n",
    "        self.gs = [1, 1]\n",
    "        self.checkpoints_path = checkpoints_path\n",
    "        self.device = device\n",
    "        self.session_name = session_name\n",
    "        self.max_epochs = max_epochs\n",
    "        self.lr = lr\n",
    "        self.wt_dec = wt_dec\n",
    "        self.start_PDA = start_PDA\n",
    "        self.init_mu = init_mu\n",
    "        self.sigma = sigma\n",
    "        self.l = l\n",
    "        self.gamma = gamma\n",
    "\n",
    "        os.makedirs(name=train_cls_log_path, exist_ok=True)\n",
    "        os.makedirs(name=val_cls_log_path, exist_ok=True)\n",
    "        os.makedirs(name=val_cam_log_path, exist_ok=True)\n",
    "        os.makedirs(name=test_cam_log_path, exist_ok=True)\n",
    "\n",
    "        self.train_cls_writer = SummaryWriter(log_dir=train_cls_log_path)\n",
    "        self.val_cls_writer = SummaryWriter(log_dir=val_cls_log_path)\n",
    "        self.val_cam_writer = SummaryWriter(log_dir=val_cam_log_path)\n",
    "        self.test_cam_writer = SummaryWriter(log_dir=test_cam_log_path)\n",
    "\n",
    "        train_cls_data, val_cls_data = datautils.split_classification_data(\n",
    "            images_path=train_data_path,\n",
    "            split_size=val_size,\n",
    "        )\n",
    "\n",
    "        self.train_cls_loader = datautils.get_LUAD_HistoSeg_classification_dataloader(\n",
    "            images_path=train_data_path,\n",
    "            image_names=train_cls_data,\n",
    "            trans=CT.Compose([\n",
    "                CT.RandomHorizontalFlip(p=0.5),\n",
    "                CT.RandomVerticalFlip(p=0.5),\n",
    "                CT.Random90Rotation(p=0.5),\n",
    "                CT.Random180Rotation(p=0.5),\n",
    "                CT.Random270Rotation(p=0.5),\n",
    "                CT.ToTensor(),\n",
    "            ]),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        self.val_cls_loader = datautils.get_LUAD_HistoSeg_classification_dataloader(\n",
    "            images_path=train_data_path,\n",
    "            image_names=val_cls_data,\n",
    "            trans=CT.Compose([\n",
    "                CT.ToTensor(),\n",
    "            ]),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        self.val_cam_loader = datautils.get_LUAD_HistoSeg_segmentation_dataloader(\n",
    "            images_path=os.path.join(val_data_path, 'img'),\n",
    "            masks_path=os.path.join(val_data_path, 'mask'),\n",
    "            trans=CT.Compose([\n",
    "                CT.ToTensor(),\n",
    "            ]),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        self.test_cam_loader = datautils.get_LUAD_HistoSeg_segmentation_dataloader(\n",
    "            images_path=os.path.join(test_data_path, 'img'),\n",
    "            masks_path=os.path.join(test_data_path, 'mask'),\n",
    "            trans=CT.Compose([\n",
    "                CT.ToTensor(),\n",
    "            ]),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        self.model = ResNet38ClassificationModel(num_classes=num_classes)\n",
    "        self.train_cls_writer.add_graph(model=self.model, input_to_model=torch.Tensor(torch.zeros(size=(1, 3, 224, 224))))\n",
    "\n",
    "        if init_weights is not None:\n",
    "            wp = os.path.join(init_weights_path, init_weights)\n",
    "\n",
    "            if init_weights[-7:] == '.params':\n",
    "                weights_dict = torchutils.convert_mxnet_weights_to_torch(weights_path=wp)\n",
    "\n",
    "                # Strict=False because of linear1000 and fc8\n",
    "                self.model.load_state_dict(state_dict=weights_dict, strict=False)\n",
    "                print('Initialize model with MXNet weights')\n",
    "\n",
    "            elif init_weights[-4:] == '.pth':\n",
    "                weights_dict = torch.load(f=wp, map_location='cpu')\n",
    "                self.model.load_state_dict(state_dict=weights_dict, strict=True)\n",
    "                print('Initialize model with user-defined weights')\n",
    "\n",
    "            else:\n",
    "                raise NotImplementedError(f'Invalid model weights {init_weights}')\n",
    "        else:\n",
    "            print('Initialize model with random weights')\n",
    "\n",
    "        param_groups = self.model.get_parameter_groups()\n",
    "\n",
    "        self.optimizer = torch.optim.SGD(params=[\n",
    "            {'params': param_groups[0], 'lr': self.lr * 0.1, 'weight_decay': self.wt_dec},\n",
    "            {'params': param_groups[1], 'lr': self.lr * 0.2, 'weight_decay': 0},\n",
    "            {'params': param_groups[2], 'lr': self.lr * 10, 'weight_decay': self.wt_dec},\n",
    "            {'params': param_groups[3], 'lr': self.lr * 20, 'weight_decay': 0},\n",
    "            {'params': param_groups[4], 'lr': self.lr * 100, 'weight_decay': self.wt_dec},\n",
    "            {'params': param_groups[5], 'lr': self.lr * 200, 'weight_decay': 0},\n",
    "        ], lr=self.lr, weight_decay=self.wt_dec)\n",
    "\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(optimizer=self.optimizer, step_size=1, gamma=0.85)\n",
    "\n",
    "        self.cls_criterion = metrics.WeightedMultiLabelSoftMarginLoss()\n",
    "        self.cls_evaluator = metrics.IoUAccuracy()\n",
    "        self.cam_evaluator = metrics.PseudoMaskEvaluator(num_classes=num_classes)\n",
    "\n",
    "    def save_checkpoint(self, epoch, history, state_dict_path):\n",
    "        state_dict = {\n",
    "            'session_name': self.session_name,\n",
    "            'epoch': epoch,\n",
    "            'global_steps': self.gs,\n",
    "\n",
    "            'train_cls_writer_logdir': self.train_cls_writer.get_logdir(),\n",
    "            'train_cls_writer_logname': self.train_cls_writer.file_writer.event_writer._file_name,\n",
    "            'val_cls_writer_logdir': self.val_cls_writer.get_logdir(),\n",
    "            'val_cls_writer_logname': self.val_cls_writer.file_writer.event_writer._file_name,\n",
    "            'val_cam_writer_logdir': self.val_cam_writer.get_logdir(),\n",
    "            'val_cam_writer_logname': self.val_cam_writer.file_writer.event_writer._file_name,\n",
    "            'test_cam_writer_logdir': self.test_cam_writer.get_logdir(),\n",
    "            'test_cam_writer_logname': self.test_cam_writer.file_writer.event_writer._file_name,\n",
    "\n",
    "            'train_cls_loader': self.train_cls_loader,\n",
    "            'val_cls_loader': self.val_cls_loader,\n",
    "            'val_cam_loader': self.val_cam_loader,\n",
    "            'test_cam_loader': self.test_cam_loader,\n",
    "\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'model_mu': self.model.mu,\n",
    "            'model_gamma': self.model.gamma,\n",
    "            'model_enable_PDA': self.model.enable_PDA,\n",
    "\n",
    "            'optimizer': self.optimizer,\n",
    "            'scheduler': self.scheduler,\n",
    "            'history': history\n",
    "        }\n",
    "\n",
    "        torch.save(obj=state_dict, f=state_dict_path)\n",
    "\n",
    "    def resume_checkpoint(self, state_dict_path=None):\n",
    "\n",
    "        state_dict = torch.load(f=state_dict_path, map_location='cpu')\n",
    "        session = state_dict['session_name']\n",
    "        assert session == self.session_name, f\"State dict {session} is not for session {self.session_name}\"\n",
    "        print('Checkpoint Loaded')\n",
    "\n",
    "        epoch = state_dict['epoch']\n",
    "        self.gs = state_dict['global_steps']\n",
    "\n",
    "        self.train_cls_writer.log_dir = state_dict['train_cls_writer_logdir']\n",
    "        self.train_cls_writer.file_writer.event_writer._file_name = state_dict['train_cls_writer_logname'],\n",
    "        self.val_cls_writer.log_dir = state_dict['val_cls_writer_logdir']\n",
    "        self.val_cls_writer.file_writer.event_writer._file_name = state_dict['val_cls_writer_logname'],\n",
    "        self.val_cam_writer.log_dir = state_dict['val_cam_writer_logdir']\n",
    "        self.val_cam_writer.file_writer.event_writer._file_name = state_dict['val_cam_writer_logname'],\n",
    "        self.test_cam_writer.log_dir = state_dict['test_cam_writer_logdir']\n",
    "        self.test_cam_writer.file_writer.event_writer._file_name = state_dict['test_cam_writer_logname'],\n",
    "\n",
    "        self.train_cls_loader = state_dict['train_cls_loader']\n",
    "        self.val_cls_loader = state_dict['val_cls_loader']\n",
    "        self.val_cam_loader = state_dict['val_cam_loader']\n",
    "        self.test_cam_loader = state_dict['test_cam_loader']\n",
    "\n",
    "        self.model.load_state_dict(state_dict=state_dict['model_state_dict'])\n",
    "        self.model.mu = state_dict['model_mu']\n",
    "        self.model.gamma = state_dict['model_gamma']\n",
    "        self.model.enable_PDA = state_dict['model_enable_PDA']\n",
    "\n",
    "        self.optimizer = state_dict['optimizer']\n",
    "        self.scheduler = state_dict['scheduler']\n",
    "        history = state_dict['history']\n",
    "\n",
    "        self.fit(ep=epoch + 1, epoch_history=history)\n",
    "\n",
    "    def train_cls_one_epoch(self, ep, thresh=0.5, print_incorrects=False):\n",
    "        print(f'{\"#\" * 20} Train Classification E{ep} {\"#\" * 20}')\n",
    "\n",
    "        h = {\n",
    "            'MLSMLoss': [],\n",
    "            'IoUAccuracy': [],\n",
    "            'ExactMatch': [],\n",
    "            'TE_IoUAccuracy': [],\n",
    "            'NEC_IoUAccuracy': [],\n",
    "            'LYM_IoUAccuracy': [],\n",
    "            'TAS_IoUAccuracy': [],\n",
    "            'TE_MLSMLoss': [],\n",
    "            'NEC_MLSMLoss': [],\n",
    "            'LYM_MLSMLoss': [],\n",
    "            'TAS_MLSMLoss': [],\n",
    "        }\n",
    "        for i, params in enumerate(self.optimizer.param_groups):\n",
    "            h[f'LRG{i}'] = []\n",
    "\n",
    "        t = tqdm(self.train_cls_loader)\n",
    "\n",
    "        for iter, sample in enumerate(t):\n",
    "            names = sample['name']\n",
    "            images = sample['img'].to(device=self.device)\n",
    "            labels = sample['label'].to(device=self.device)\n",
    "\n",
    "            x = self.model(images)\n",
    "            x = x.view(x.size(0), -1)\n",
    "\n",
    "            loss_class = self.cls_criterion.train_call(input=x, target=labels)\n",
    "\n",
    "            loss = loss_class.mean()\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            loss = loss.item()\n",
    "            loss_class = loss_class.detach().cpu().numpy()\n",
    "            probs = torch.sigmoid(input=x).detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "\n",
    "            scores = self.cls_evaluator(probs=probs, y=labels)\n",
    "\n",
    "            if print_incorrects:\n",
    "                torchutils.print_incorrects(names=names, probs=probs, labels=labels, thresh=thresh)\n",
    "\n",
    "            h['MLSMLoss'].append(loss)\n",
    "            h['IoUAccuracy'].append(scores['accuracy'])\n",
    "            h['ExactMatch'].append(scores['exact_match'])\n",
    "            h['TE_IoUAccuracy'].append(scores['class_acc'][0])\n",
    "            h['NEC_IoUAccuracy'].append(scores['class_acc'][1])\n",
    "            h['LYM_IoUAccuracy'].append(scores['class_acc'][2])\n",
    "            h['TAS_IoUAccuracy'].append(scores['class_acc'][3])\n",
    "            h['TE_MLSMLoss'].append(loss_class[0])\n",
    "            h['NEC_MLSMLoss'].append(loss_class[1])\n",
    "            h['LYM_MLSMLoss'].append(loss_class[2])\n",
    "            h['TAS_MLSMLoss'].append(loss_class[3])\n",
    "\n",
    "            self.train_cls_writer.add_scalar(tag='Batch/MLSMLoss', scalar_value=loss, global_step=self.gs[0])\n",
    "            self.train_cls_writer.add_scalar(tag='Batch/IoUAccuracy', scalar_value=scores['accuracy'], global_step=self.gs[0])\n",
    "            self.train_cls_writer.add_scalar(tag='Batch/ExactMatch', scalar_value=scores['exact_match'], global_step=self.gs[0])\n",
    "            self.train_cls_writer.add_scalar(tag='Batch/TE_IoUAccuracy', scalar_value=scores['class_acc'][0], global_step=self.gs[0])\n",
    "            self.train_cls_writer.add_scalar(tag='Batch/NEC_IoUAccuracy', scalar_value=scores['class_acc'][1], global_step=self.gs[0])\n",
    "            self.train_cls_writer.add_scalar(tag='Batch/LYM_IoUAccuracy', scalar_value=scores['class_acc'][2], global_step=self.gs[0])\n",
    "            self.train_cls_writer.add_scalar(tag='Batch/TAS_IoUAccuracy', scalar_value=scores['class_acc'][3], global_step=self.gs[0])\n",
    "            self.train_cls_writer.add_scalar(tag='Batch/TE_MLSMLoss', scalar_value=loss_class[0], global_step=self.gs[0])\n",
    "            self.train_cls_writer.add_scalar(tag='Batch/NEC_MLSMLoss', scalar_value=loss_class[1], global_step=self.gs[0])\n",
    "            self.train_cls_writer.add_scalar(tag='Batch/LYM_MLSMLoss', scalar_value=loss_class[2], global_step=self.gs[0])\n",
    "            self.train_cls_writer.add_scalar(tag='Batch/TAS_MLSMLoss', scalar_value=loss_class[3], global_step=self.gs[0])\n",
    "\n",
    "            for i, params in enumerate(self.optimizer.param_groups):\n",
    "                self.train_cls_writer.add_scalar(tag=f'Batch/LRG{i}', scalar_value=params['lr'], global_step=self.gs[0])\n",
    "                h[f'LRG{i}'].append(params['lr'])\n",
    "\n",
    "            self.gs[0] += 1\n",
    "\n",
    "            t.set_description(\n",
    "                desc=f\"E{ep} Train Loss: {loss:0.4f}, \"\n",
    "                f\"Acc: {scores['accuracy']:0.4f}, \"\n",
    "                f\"EM: {scores['exact_match']:0.4f}, \"\n",
    "            )\n",
    "\n",
    "        self.train_cls_writer.add_scalar(tag='Epoch/MLSMLoss', scalar_value=np.nanmean(h['MLSMLoss']), global_step=ep)\n",
    "        self.train_cls_writer.add_scalar(tag='Epoch/IoUAccuracy', scalar_value=np.nanmean(h['IoUAccuracy']), global_step=ep)\n",
    "        self.train_cls_writer.add_scalar(tag='Epoch/ExactMatch', scalar_value=np.nanmean(h['ExactMatch']), global_step=ep)\n",
    "        self.train_cls_writer.add_scalar(tag='Epoch/TE_IoUAccuracy', scalar_value=np.nanmean(h['TE_IoUAccuracy']), global_step=ep)\n",
    "        self.train_cls_writer.add_scalar(tag='Epoch/NEC_IoUAccuracy', scalar_value=np.nanmean(h['NEC_IoUAccuracy']), global_step=ep)\n",
    "        self.train_cls_writer.add_scalar(tag='Epoch/LYM_IoUAccuracy', scalar_value=np.nanmean(h['LYM_IoUAccuracy']), global_step=ep)\n",
    "        self.train_cls_writer.add_scalar(tag='Epoch/TAS_IoUAccuracy', scalar_value=np.nanmean(h['TAS_IoUAccuracy']), global_step=ep)\n",
    "        self.train_cls_writer.add_scalar(tag='Epoch/TE_MLSMLoss', scalar_value=np.nanmean(h['TE_MLSMLoss']), global_step=ep)\n",
    "        self.train_cls_writer.add_scalar(tag='Epoch/NEC_MLSMLoss', scalar_value=np.nanmean(h['NEC_MLSMLoss']), global_step=ep)\n",
    "        self.train_cls_writer.add_scalar(tag='Epoch/LYM_MLSMLoss', scalar_value=np.nanmean(h['LYM_MLSMLoss']), global_step=ep)\n",
    "        self.train_cls_writer.add_scalar(tag='Epoch/TAS_MLSMLoss', scalar_value=np.nanmean(h['TAS_MLSMLoss']), global_step=ep)\n",
    "\n",
    "        # for i, epda in enumerate(self.model.enable_PDA):\n",
    "        #     self.train_cls_writer.add_scalar(tag=f'Epoch/Enable_PDA{i}', scalar_value=epda, global_step=ep)\n",
    "        #\n",
    "        # for i, mu in enumerate(self.model.mu):\n",
    "        #     self.train_cls_writer.add_scalar(tag=f'Epoch/Mu{i}', scalar_value=mu, global_step=ep)\n",
    "        #\n",
    "        # for i, gamma in enumerate(self.model.gamma):\n",
    "        #     self.train_cls_writer.add_scalar(tag=f'Epoch/Gamma{i}', scalar_value=gamma, global_step=ep)\n",
    "\n",
    "        for k, v in h.items():\n",
    "            print(f'Train Classification {k}: {np.nanmean(h[k]):0.4f}')\n",
    "        print(f'Train Classification model_enable_PDA: {self.model.enable_PDA}')\n",
    "        print(f'Train Classification model_mu: {self.model.mu}')\n",
    "        print(f'Train Classification model_gamma: {self.model.gamma}')\n",
    "        return h\n",
    "\n",
    "    def validate_cls_one_epoch(self, ep, thresh=0.5, print_incorrects=False):\n",
    "        print(f'{\"#\" * 20} Validating Classification E{ep} {\"#\" * 20}')\n",
    "\n",
    "        h = {\n",
    "            'MLSMLoss': [],\n",
    "            'IoUAccuracy': [],\n",
    "            'ExactMatch': [],\n",
    "            'TE_IoUAccuracy': [],\n",
    "            'NEC_IoUAccuracy': [],\n",
    "            'LYM_IoUAccuracy': [],\n",
    "            'TAS_IoUAccuracy': [],\n",
    "            'TE_MLSMLoss': [],\n",
    "            'NEC_MLSMLoss': [],\n",
    "            'LYM_MLSMLoss': [],\n",
    "            'TAS_MLSMLoss': [],\n",
    "        }\n",
    "\n",
    "        t = tqdm(self.val_cls_loader)\n",
    "\n",
    "        for iter, sample in enumerate(t):\n",
    "            names = sample['name']\n",
    "            images = sample['img'].to(device=self.device)\n",
    "            labels = sample['label'].to(device=self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                x = self.model(images)\n",
    "                x = x.view(x.size(0), -1)\n",
    "\n",
    "            loss_class = self.cls_criterion.val_call(input=x, target=labels)\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            loss_class = loss_class.detach().cpu().numpy()\n",
    "            loss = loss_class.mean()\n",
    "            probs = torch.sigmoid(input=x).detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "\n",
    "            scores = self.cls_evaluator(probs=probs, y=labels)\n",
    "\n",
    "            if print_incorrects:\n",
    "                torchutils.print_incorrects(names=names, probs=probs, labels=labels, thresh=thresh)\n",
    "\n",
    "            h['MLSMLoss'].append(loss)\n",
    "            h['IoUAccuracy'].append(scores['accuracy'])\n",
    "            h['ExactMatch'].append(scores['exact_match'])\n",
    "            h['TE_IoUAccuracy'].append(scores['class_acc'][0])\n",
    "            h['NEC_IoUAccuracy'].append(scores['class_acc'][1])\n",
    "            h['LYM_IoUAccuracy'].append(scores['class_acc'][2])\n",
    "            h['TAS_IoUAccuracy'].append(scores['class_acc'][3])\n",
    "            h['TE_MLSMLoss'].append(loss_class[0])\n",
    "            h['NEC_MLSMLoss'].append(loss_class[1])\n",
    "            h['LYM_MLSMLoss'].append(loss_class[2])\n",
    "            h['TAS_MLSMLoss'].append(loss_class[3])\n",
    "\n",
    "            t.set_description(\n",
    "                desc=f\"E{ep} Val Loss: {loss:0.4f}, \"\n",
    "                f\"Acc: {scores['accuracy']:0.4f}, \"\n",
    "                f\"EM: {scores['exact_match']:0.4f}, \"\n",
    "            )\n",
    "\n",
    "            self.val_cls_writer.add_scalar(tag='Batch/MLSMLoss', scalar_value=loss, global_step=self.gs[1])\n",
    "            self.val_cls_writer.add_scalar(tag='Batch/IoUAccuracy', scalar_value=scores['accuracy'], global_step=self.gs[1])\n",
    "            self.val_cls_writer.add_scalar(tag='Batch/ExactMatch', scalar_value=scores['exact_match'], global_step=self.gs[1])\n",
    "            self.val_cls_writer.add_scalar(tag='Batch/TE_IoUAccuracy', scalar_value=scores['class_acc'][0], global_step=self.gs[1])\n",
    "            self.val_cls_writer.add_scalar(tag='Batch/NEC_IoUAccuracy', scalar_value=scores['class_acc'][1], global_step=self.gs[1])\n",
    "            self.val_cls_writer.add_scalar(tag='Batch/LYM_IoUAccuracy', scalar_value=scores['class_acc'][2], global_step=self.gs[1])\n",
    "            self.val_cls_writer.add_scalar(tag='Batch/TAS_IoUAccuracy', scalar_value=scores['class_acc'][3], global_step=self.gs[1])\n",
    "            self.val_cls_writer.add_scalar(tag='Batch/TE_MLSMLoss', scalar_value=loss_class[0], global_step=self.gs[1])\n",
    "            self.val_cls_writer.add_scalar(tag='Batch/NEC_MLSMLoss', scalar_value=loss_class[1], global_step=self.gs[1])\n",
    "            self.val_cls_writer.add_scalar(tag='Batch/LYM_MLSMLoss', scalar_value=loss_class[2], global_step=self.gs[1])\n",
    "            self.val_cls_writer.add_scalar(tag='Batch/TAS_MLSMLoss', scalar_value=loss_class[3], global_step=self.gs[1])\n",
    "\n",
    "            self.gs[1] += 1\n",
    "\n",
    "        self.val_cls_writer.add_scalar(tag='Epoch/MLSMLoss', scalar_value=np.nanmean(h['MLSMLoss']), global_step=ep)\n",
    "        self.val_cls_writer.add_scalar(tag='Epoch/IoUAccuracy', scalar_value=np.nanmean(h['IoUAccuracy']), global_step=ep)\n",
    "        self.val_cls_writer.add_scalar(tag='Epoch/ExactMatch', scalar_value=np.nanmean(h['ExactMatch']), global_step=ep)\n",
    "        self.val_cls_writer.add_scalar(tag='Epoch/TE_IoUAccuracy', scalar_value=np.nanmean(h['TE_IoUAccuracy']), global_step=ep)\n",
    "        self.val_cls_writer.add_scalar(tag='Epoch/NEC_IoUAccuracy', scalar_value=np.nanmean(h['NEC_IoUAccuracy']), global_step=ep)\n",
    "        self.val_cls_writer.add_scalar(tag='Epoch/LYM_IoUAccuracy', scalar_value=np.nanmean(h['LYM_IoUAccuracy']), global_step=ep)\n",
    "        self.val_cls_writer.add_scalar(tag='Epoch/TAS_IoUAccuracy', scalar_value=np.nanmean(h['TAS_IoUAccuracy']), global_step=ep)\n",
    "        self.val_cls_writer.add_scalar(tag='Epoch/TE_MLSMLoss', scalar_value=np.nanmean(h['TE_MLSMLoss']), global_step=ep)\n",
    "        self.val_cls_writer.add_scalar(tag='Epoch/NEC_MLSMLoss', scalar_value=np.nanmean(h['NEC_MLSMLoss']), global_step=ep)\n",
    "        self.val_cls_writer.add_scalar(tag='Epoch/LYM_MLSMLoss', scalar_value=np.nanmean(h['LYM_MLSMLoss']), global_step=ep)\n",
    "        self.val_cls_writer.add_scalar(tag='Epoch/TAS_MLSMLoss', scalar_value=np.nanmean(h['TAS_MLSMLoss']), global_step=ep)\n",
    "\n",
    "        for k, v in h.items():\n",
    "            print(f'Validate Classification {k}: {np.nanmean(h[k]):0.4f}')\n",
    "        print(f'Validate Classification model_enable_PDA: {self.model.enable_PDA}')\n",
    "        print(f'Validate Classification model_mu: {self.model.mu}')\n",
    "        print(f'Train Classification model_gamma: {self.model.gamma}')\n",
    "\n",
    "        return h\n",
    "\n",
    "    def validate_cam_one_epoch(self, ep=1, threshold=0.25):\n",
    "        print(f'{\"#\" * 20} Validating CAMs E{ep} {\"#\" * 20}')\n",
    "\n",
    "        t = tqdm(self.val_cam_loader, desc=f'E{ep} Validating CAMs')\n",
    "\n",
    "        for iter, sample in enumerate(t):\n",
    "            names = sample['name']\n",
    "            images = sample['img'].to(device=self.device)\n",
    "            masks = sample['mask'].numpy()\n",
    "\n",
    "            b, c, h, w = images.size()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                cams, labels = self.model.forward_cam(images)\n",
    "\n",
    "            cams = cams.detach().cpu()\n",
    "            labels = labels.detach().cpu()\n",
    "\n",
    "            labels = torch.greater(input=labels, other=threshold)\n",
    "            cams = F.interpolate(input=cams, size=(h, w), mode='bilinear', align_corners=False)\n",
    "\n",
    "            cams = cams.numpy()\n",
    "            labels = labels.numpy()\n",
    "\n",
    "            cams = cams * labels\n",
    "            cams = np.argmax(a=cams, axis=1).astype(dtype=np.uint8)\n",
    "\n",
    "            cams[masks == 4] = 4\n",
    "            self.cam_evaluator.add_batch(gt_mask=masks, pred_mask=cams)\n",
    "\n",
    "        scores = self.cam_evaluator.get_scores()\n",
    "\n",
    "        self.val_cam_writer.add_scalar(tag='Epoch/PixelAccuracy', scalar_value=scores['pa'], global_step=ep)\n",
    "        self.val_cam_writer.add_scalar(tag='Epoch/MeanClassAccuracy', scalar_value=scores['ma'], global_step=ep)\n",
    "        self.val_cam_writer.add_scalar(tag='Epoch/TE_IoUAccuracy', scalar_value=scores['iou'][0], global_step=ep)\n",
    "        self.val_cam_writer.add_scalar(tag='Epoch/NEC_IoUAccuracy', scalar_value=scores['iou'][1], global_step=ep)\n",
    "        self.val_cam_writer.add_scalar(tag='Epoch/LYM_IoUAccuracy', scalar_value=scores['iou'][2], global_step=ep)\n",
    "        self.val_cam_writer.add_scalar(tag='Epoch/TAS_IoUAccuracy', scalar_value=scores['iou'][3], global_step=ep)\n",
    "        self.val_cam_writer.add_scalar(tag='Epoch/MIoU', scalar_value=scores['miou'], global_step=ep)\n",
    "        self.val_cam_writer.add_scalar(tag='Epoch/FWIoU', scalar_value=scores['fwiou'], global_step=ep)\n",
    "\n",
    "        for k, v in scores.items():\n",
    "            print(f'Validate CAMs {k}: {np.nanmean(scores[k]):0.4f}')\n",
    "        print(f'Validate CAMs model_enable_PDA: {self.model.enable_PDA}')\n",
    "        print(f'Validate CAMs model_mu: {self.model.mu}')\n",
    "        print(f'Validate CAMs model_gamma: {self.model.gamma}')\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def test_cam_one_epoch(self, ep=1, threshold=0.25):\n",
    "        print(f'{\"#\" * 20} Testing CAMs E{ep} {\"#\" * 20}')\n",
    "\n",
    "        t = tqdm(self.test_cam_loader, desc=f'E{ep} Testing CAMs')\n",
    "\n",
    "        for iter, sample in enumerate(t):\n",
    "            names = sample['name']\n",
    "            images = sample['img'].to(device=self.device)\n",
    "            masks = sample['mask'].numpy()\n",
    "\n",
    "            b, c, h, w = images.size()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                cams, labels = self.model.forward_cam(images)\n",
    "\n",
    "            cams = cams.detach().cpu()\n",
    "            labels = labels.detach().cpu()\n",
    "\n",
    "            labels = torch.greater(input=labels, other=threshold)\n",
    "            cams = F.interpolate(input=cams, size=(h, w), mode='bilinear', align_corners=False)\n",
    "\n",
    "            cams = cams.numpy()\n",
    "            labels = labels.numpy()\n",
    "\n",
    "            cams = cams * labels\n",
    "            cams = np.argmax(a=cams, axis=1).astype(dtype=np.uint8)\n",
    "\n",
    "            cams[masks == 4] = 4\n",
    "            self.cam_evaluator.add_batch(gt_mask=masks, pred_mask=cams)\n",
    "\n",
    "        scores = self.cam_evaluator.get_scores()\n",
    "\n",
    "        self.test_cam_writer.add_scalar(tag='Epoch/PixelAccuracy', scalar_value=scores['pa'], global_step=ep)\n",
    "        self.test_cam_writer.add_scalar(tag='Epoch/MeanClassAccuracy', scalar_value=scores['ma'], global_step=ep)\n",
    "        self.test_cam_writer.add_scalar(tag='Epoch/TE_IoUAccuracy', scalar_value=scores['iou'][0], global_step=ep)\n",
    "        self.test_cam_writer.add_scalar(tag='Epoch/NEC_IoUAccuracy', scalar_value=scores['iou'][1], global_step=ep)\n",
    "        self.test_cam_writer.add_scalar(tag='Epoch/LYM_IoUAccuracy', scalar_value=scores['iou'][2], global_step=ep)\n",
    "        self.test_cam_writer.add_scalar(tag='Epoch/TAS_IoUAccuracy', scalar_value=scores['iou'][3], global_step=ep)\n",
    "        self.test_cam_writer.add_scalar(tag='Epoch/MIoU', scalar_value=scores['miou'], global_step=ep)\n",
    "        self.test_cam_writer.add_scalar(tag='Epoch/FWIoU', scalar_value=scores['fwiou'], global_step=ep)\n",
    "\n",
    "        for k, v in scores.items():\n",
    "            print(f'Test CAMs {k}: {np.nanmean(scores[k]):0.4f}')\n",
    "        print(f'Test CAMs model_enable_PDA: {self.model.enable_PDA}')\n",
    "        print(f'Test CAMs model_mu: {self.model.mu}')\n",
    "        print(f'Test CAMs model_gamma: {self.model.gamma}')\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def fit(self, ep=1, epoch_history=None):\n",
    "        self.model = self.model.to(device=self.device)\n",
    "\n",
    "        wp = os.path.join(self.checkpoints_path, 'weights')\n",
    "        os.makedirs(name=wp, exist_ok=True)\n",
    "\n",
    "        if epoch_history is None:\n",
    "            epoch_history = {\n",
    "                'train_cls': [],\n",
    "                'val_cls': [],\n",
    "                'val_cam': [],\n",
    "                'test_cam': [],\n",
    "            }\n",
    "\n",
    "        for ep in range(ep, self.max_epochs + 1):\n",
    "\n",
    "            ########################################################\n",
    "            #        Start of Transfer Learning Trade off\n",
    "            ########################################################\n",
    "            if ep < 4:\n",
    "                self.model.train(TL=True)\n",
    "            else:\n",
    "                self.model.train(TL=False)\n",
    "            ########################################################\n",
    "            #        End of Transfer Learning Trade off\n",
    "            ########################################################\n",
    "\n",
    "            ########################################################\n",
    "            #        Start of Progressive Dropout Attention\n",
    "            ########################################################\n",
    "            # if ep >= self.start_PDA:  # 7\n",
    "            #     self.model.enable_PDA[0] = True\n",
    "            #     if ep >= self.start_PDA + 5:\n",
    "            #         self.model.enable_PDA[1] = True\n",
    "            #     if ep >= self.start_PDA + 15:\n",
    "            #         self.model.enable_PDA[2] = True\n",
    "            #     if ep >= self.start_PDA + 20:\n",
    "            #         self.model.enable_PDA[3] = True\n",
    "            #     if ep >= self.start_PDA + 25:\n",
    "            #         self.model.enable_PDA[4] = True\n",
    "            #\n",
    "            #     for i, pda in enumerate(self.model.enable_PDA):\n",
    "            #         if pda:\n",
    "            #             if self.model.mu[i] > self.l:\n",
    "            #                 self.model.mu[i] = self.model.mu[i] * self.sigma\n",
    "            #             # if self.model.gamma[i] < 0.3:\n",
    "            #             #     self.model.gamma[i] = self.model.gamma[i] + self.gamma\n",
    "            # else:\n",
    "            #     self.model.enable_PDA = [False, False, False, False, False]\n",
    "            ########################################################\n",
    "            #        End of Progressive Dropout Attention\n",
    "            ########################################################\n",
    "\n",
    "            \"\"\" Training Classification \"\"\"\n",
    "            epoch_history['train_cls'].append(self.train_cls_one_epoch(ep=ep))\n",
    "\n",
    "            \"\"\" Validating Classification \"\"\"\n",
    "            self.model.eval()\n",
    "            self.model.enable_PDA = [False, False, False, False, False]\n",
    "            epoch_history['val_cls'].append(self.validate_cls_one_epoch(ep=ep))\n",
    "\n",
    "            \"\"\" Validating CAMs \"\"\"\n",
    "            self.cam_evaluator.reset()\n",
    "            epoch_history['val_cam'].append(self.validate_cam_one_epoch(ep=ep))\n",
    "\n",
    "            \"\"\" Testing CAMs \"\"\"\n",
    "            self.cam_evaluator.reset()\n",
    "            epoch_history['test_cam'].append(self.test_cam_one_epoch(ep=ep))\n",
    "\n",
    "            self.scheduler.step()\n",
    "\n",
    "            wn = f'{self.session_name}_E{ep}_checkpoint_trained_on_luad.pth'\n",
    "\n",
    "            self.save_checkpoint(epoch=ep, history=epoch_history, state_dict_path=os.path.join(wp, wn))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def final_forward_PDA(x, w, mu, gamma):  # (b, 4096, 28, 28), (4, 4096, 1, 1)\n",
    "\n",
    "    cam = torch.conv2d(input=x, weight=w)  # (b, 4, 28, 28)\n",
    "    cam = torch.relu(input=cam)  # (b, 4, 28, 28)\n",
    "\n",
    "    beta = torch.amax(input=cam, dim=(-2, -1), keepdim=True) * mu  # (b, 4, 1, 1)\n",
    "    beta = beta.expand(size=cam.size())  # (b, 4, 28, 28)\n",
    "\n",
    "    alpha = torch.amin(input=cam, dim=(-2, -1), keepdim=True) + gamma  # (b, 4, 1, 1)\n",
    "    alpha = alpha.expand(size=cam.size())  # (b, 4, 28, 28)\n",
    "\n",
    "    cam = torch.less(input=cam, other=beta) * torch.greater(input=cam, other=alpha) * cam  # (b, 4, 28, 28)\n",
    "\n",
    "    cam = torch.mean(input=cam, dim=1, keepdim=True)  # (b, 1, 28, 28)\n",
    "\n",
    "    x = x * cam  # (b, 4096, 28, 28)\n",
    "\n",
    "    return x  # (b, 4096, 28, 28)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def intermediate_forward_PDA(x, cam, mu, gamma):\n",
    "    print(x.size())\n",
    "    print(cam.size())\n",
    "\n",
    "    cam = F.interpolate(input=cam, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
    "    # for i, e in enumerate(['TE', 'NEC', 'LYM', 'TAS']):\n",
    "    #     plt.imshow(cam[0, i].detach().cpu())\n",
    "    #     plt.grid(visible=False)\n",
    "    #     plt.colorbar()\n",
    "    #     plt.title(label=f'Orig {e}')\n",
    "    #     plt.show()\n",
    "\n",
    "    x_mean = x.mean(dim=1, keepdim=True)\n",
    "    plt.matshow(x_mean[0, 0].detach().cpu())\n",
    "    plt.grid(visible=False)\n",
    "    plt.colorbar()\n",
    "    plt.title(label=f'X-Mean')\n",
    "    plt.show()\n",
    "\n",
    "    # cam = x_mean * cam\n",
    "    # for i, e in enumerate(['TE', 'NEC', 'LYM', 'TAS']):\n",
    "    #     plt.imshow(cam[0, i].detach().cpu())\n",
    "    #     plt.grid(visible=False)\n",
    "    #     plt.colorbar()\n",
    "    #     plt.title(label=f'After X*CAM {e}')\n",
    "    #     plt.show()\n",
    "\n",
    "    beta = x_mean.amax(dim=(-2, -1), keepdim=True) * 0.6  # (b, num_classes, 1, 1)\n",
    "    beta = beta.expand(size=x_mean.size())  # (b, num_classes, h, w)\n",
    "\n",
    "    alpha = x_mean.amin(dim=(-2, -1), keepdim=True) + gamma  # (b, num_classes, 1, 1)\n",
    "    alpha = alpha.expand(size=x_mean.size())  # (b, num_classes, h, w)\n",
    "\n",
    "    x_mean = torch.less(input=x_mean, other=beta) * torch.greater(input=x_mean, other=alpha) * x_mean  # (b, num_classes, h, w)\n",
    "    # for i, e in enumerate(['TE', 'NEC', 'LYM', 'TAS']):\n",
    "    #     plt.imshow(cam[0, i].detach().cpu())\n",
    "    #     plt.grid(visible=False)\n",
    "    #     plt.colorbar()\n",
    "    #     plt.title(label=f'After PDA {e}')\n",
    "    #     plt.show()\n",
    "\n",
    "    x_mean = x_mean.mean(dim=1, keepdim=True)\n",
    "    # cam = (cam > 0) * 1.0\n",
    "    plt.imshow(x_mean[0, 0].detach().cpu())\n",
    "    plt.grid(visible=False)\n",
    "    plt.colorbar()\n",
    "    plt.title(label='Mean after PDA')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    x = x * x_mean  # (b, c, h, w)\n",
    "    # plt.imshow(x.mean(dim=1, keepdim=True)[0, 0].detach().cpu())\n",
    "    # plt.grid(visible=False)\n",
    "    # plt.colorbar()\n",
    "    # plt.title(label='X-Mean-Final')\n",
    "    # plt.show()\n",
    "\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "session_name = 'Base7'\n",
    "root_path = os.getcwd()\n",
    "checkpoints_path = os.path.join(root_path, 'test', session_name)\n",
    "\n",
    "train_cls_log_path = os.path.join(checkpoints_path, 'train_cls')\n",
    "val_cls_log_path = os.path.join(checkpoints_path, 'val_cls')\n",
    "val_cam_log_path = os.path.join(checkpoints_path, 'val_cam')\n",
    "test_cam_log_path = os.path.join(checkpoints_path, 'test_cam')\n",
    "\n",
    "train_data_path = os.path.join('test', 'data')\n",
    "val_data_path = os.path.join('datasets', 'LUAD-HistoSeg', 'val')\n",
    "test_data_path = os.path.join('datasets', 'LUAD-HistoSeg', 'test')\n",
    "\n",
    "init_weights = 'ilsvrc-cls_rna-a1_cls1000_ep-0001.params'\n",
    "init_weights_path = os.path.join(root_path, 'init_weights')\n",
    "resume_path = 'test/Base7/weights/Base7_E3_checkpoint_trained_on_luad.pth'\n",
    "# resume_path = None\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "val_size = 200\n",
    "batch_size = 4\n",
    "num_classes = 4\n",
    "seed = 42\n",
    "max_epochs = 40\n",
    "lr = 1e-5\n",
    "wt_dec = 5e-4\n",
    "start_PDA = 5\n",
    "init_mu = 1\n",
    "sigma = 0.985\n",
    "l = 0.65\n",
    "gamma = 0.015\n",
    "\n",
    "pyutils.set_seed(seed=seed)\n",
    "\n",
    "engine = Engine(\n",
    "    train_cls_log_path=train_cls_log_path,\n",
    "    val_cls_log_path=val_cls_log_path,\n",
    "    val_cam_log_path=val_cam_log_path,\n",
    "    test_cam_log_path=test_cam_log_path,\n",
    "\n",
    "    train_data_path=train_data_path,\n",
    "    val_data_path=val_data_path,\n",
    "    test_data_path=test_data_path,\n",
    "\n",
    "    init_weights=init_weights,\n",
    "    init_weights_path=init_weights_path,\n",
    "\n",
    "    checkpoints_path=checkpoints_path,\n",
    "\n",
    "    device=device,\n",
    "    val_size=val_size,\n",
    "    batch_size=batch_size,\n",
    "    num_classes=num_classes,\n",
    "    session_name=session_name,\n",
    "    max_epochs=max_epochs,\n",
    "    lr=lr,\n",
    "    wt_dec=wt_dec,\n",
    "    start_PDA=start_PDA,\n",
    "    sigma=sigma,\n",
    "    l=l,\n",
    "    gamma=gamma\n",
    ")\n",
    "\n",
    "if (resume_path is not None) and (os.path.exists(path=resume_path) or os.path.exists(path=os.path.join(root_path, resume_path))):\n",
    "    print('State Dict Found')\n",
    "    engine.resume_checkpoint(state_dict_path=resume_path)\n",
    "else:\n",
    "    print('Training from scratch')\n",
    "    engine.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
